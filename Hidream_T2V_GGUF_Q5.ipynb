{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hidream_GGUF_Q5 for Text to Image Generation**\n",
        "- Choose one of the three HiDream model versions before setting up the environment.\n",
        "\n",
        "- The notebook is divided into three sections for image generation, each pre-configured with the settings that have been used to get good results for its corresponding model version.\n",
        "\n",
        "- The full version is much better than the others, but it took almost 21 minutes to generate an image with the default settings on the free T4 GPU."
      ],
      "metadata": {
        "id": "qOMU9X8Yi19t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "982f7zyAZzdc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Setup Environment\n",
        "%cd /content\n",
        "\n",
        "from IPython.display import clear_output\n",
        "# !pip install -q torchsde einops diffusers accelerate xformers\n",
        "# !git clone https://github.com/comfyanonymous/ComfyUI\n",
        "!git clone https://github.com/Isi-dev/ComfyUI\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone --branch forHidream https://github.com/Isi-dev/ComfyUI_GGUF.git\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n",
        "%cd /content/ComfyUI\n",
        "# !apt -y install -qq aria2\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "def install_pip_packages():\n",
        "    packages = [\n",
        "        'torchsde',\n",
        "        # 'av',\n",
        "        'diffusers',\n",
        "        # 'transformers',\n",
        "        'xformers',\n",
        "        'accelerate',\n",
        "        # 'omegaconf',\n",
        "        # 'tqdm',\n",
        "        # 'librosa',\n",
        "        'einops'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            # Run pip install silently (using -q)\n",
        "            subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
        "                check=True,\n",
        "                capture_output=True\n",
        "            )\n",
        "            print(f\"✓ {package} installed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ Error installing {package}: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
        "\n",
        "def install_apt_packages():\n",
        "    packages = ['aria2']\n",
        "\n",
        "    try:\n",
        "        # Run apt install silently (using -qq)\n",
        "        subprocess.run(\n",
        "            ['apt-get', '-y', 'install', '-qq'] + packages,\n",
        "            check=True,\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(\"✓ apt packages installed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ Error installing apt packages: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
        "\n",
        "# Run installations\n",
        "print(\"Installing pip packages...\")\n",
        "install_pip_packages()\n",
        "clear_output()  # Clear the pip installation output\n",
        "\n",
        "print(\"Installing apt packages...\")\n",
        "install_apt_packages()\n",
        "clear_output()  # Clear the apt installation output\n",
        "\n",
        "print(\"Installation completed with status:\")\n",
        "print(\"- All pip packages installed successfully\" if '✗' not in install_pip_packages.__code__.co_consts else \"- Some pip packages had issues\")\n",
        "print(\"- apt packages installed successfully\" if '✗' not in install_apt_packages.__code__.co_consts else \"- apt packages had issues\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import os\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from comfy import model_management\n",
        "\n",
        "from nodes import (\n",
        "    KSampler,\n",
        "    VAEDecode,\n",
        "    VAELoader,\n",
        "    CLIPTextEncode,\n",
        "    SaveImage\n",
        ")\n",
        "\n",
        "from custom_nodes.ComfyUI_GGUF.nodes import (\n",
        "    UnetLoaderGGUF,\n",
        "    QuadrupleCLIPLoaderGGUF\n",
        ")\n",
        "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
        "from comfy_extras.nodes_sd3 import EmptySD3LatentImage\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def model_download(url: str, dest_dir: str, filename: str = None, silent: bool = True) -> bool:\n",
        "    \"\"\"\n",
        "    Colab-optimized download with aria2c\n",
        "\n",
        "    Args:\n",
        "        url: Download URL\n",
        "        dest_dir: Target directory (will be created if needed)\n",
        "        filename: Optional output filename (defaults to URL filename)\n",
        "        silent: If True, suppresses all output (except errors)\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successful, False if failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create destination directory\n",
        "        Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Set filename if not specified\n",
        "        if filename is None:\n",
        "            filename = url.split('/')[-1].split('?')[0]  # Remove URL parameters\n",
        "\n",
        "        # Build command\n",
        "        cmd = [\n",
        "            'aria2c',\n",
        "            '--console-log-level=error',\n",
        "            '-c', '-x', '16', '-s', '16', '-k', '1M',\n",
        "            '-d', dest_dir,\n",
        "            '-o', filename,\n",
        "            url\n",
        "        ]\n",
        "\n",
        "        # Add silent flags if requested\n",
        "        if silent:\n",
        "            cmd.extend(['--summary-interval=0', '--quiet'])\n",
        "            print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
        "\n",
        "        # Run download\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "\n",
        "        if silent:\n",
        "            print(\"Done!\")\n",
        "        else:\n",
        "            print(f\"Downloaded {filename} to {dest_dir}\")\n",
        "        return filename\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        error = e.stderr.strip() or \"Unknown error\"\n",
        "        print(f\"\\nError downloading {filename}: {error}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "hidream_version = \"full\" # @param [\"fast\", \"dev\", \"full\"]\n",
        "\n",
        "hidream_model = \"hidream-i1-dev-Q5_0.gguf\"\n",
        "\n",
        "if hidream_version == \"fast\":\n",
        "    hidream_model = model_download(\"https://huggingface.co/city96/HiDream-I1-Fast-gguf/resolve/main/hidream-i1-fast-Q5_0.gguf\", \"/content/ComfyUI/models/diffusion_models\")\n",
        "elif hidream_version == \"full\":\n",
        "    hidream_model = model_download(\"https://huggingface.co/city96/HiDream-I1-Full-gguf/resolve/main/hidream-i1-full-Q5_0.gguf\", \"/content/ComfyUI/models/diffusion_models\")\n",
        "else:\n",
        "    model_download(\"https://huggingface.co/city96/HiDream-I1-Dev-gguf/resolve/main/hidream-i1-dev-Q5_0.gguf\", \"/content/ComfyUI/models/diffusion_models\")\n",
        "\n",
        "clip_g = model_download(\"https://huggingface.co/Comfy-Org/HiDream-I1_ComfyUI/resolve/main/split_files/text_encoders/clip_g_hidream.safetensors\", \"/content/ComfyUI/models/text_encoders\")\n",
        "clip_l = model_download(\"https://huggingface.co/Comfy-Org/HiDream-I1_ComfyUI/resolve/main/split_files/text_encoders/clip_l_hidream.safetensors\", \"/content/ComfyUI/models/text_encoders\")\n",
        "llama = model_download(\"https://huggingface.co/calcuis/hidream-gguf/resolve/main/llama-q2_k.gguf\", \"/content/ComfyUI/models/text_encoders\")\n",
        "t5xxl = model_download(\"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q6_K.gguf\", \"/content/ComfyUI/models/text_encoders\")\n",
        "model_download(\"https://huggingface.co/Comfy-Org/HiDream-I1_ComfyUI/resolve/main/split_files/vae/ae.safetensors\", \"/content/ComfyUI/models/vae\")\n",
        "\n",
        "# Initialize nodes\n",
        "unet_loader = UnetLoaderGGUF()\n",
        "model_sampling = ModelSamplingSD3()\n",
        "clip_loader = QuadrupleCLIPLoaderGGUF()\n",
        "clip_encode_positive = CLIPTextEncode()\n",
        "clip_encode_negative = CLIPTextEncode()\n",
        "vae_loader = VAELoader()\n",
        "empty_latent_image = EmptySD3LatentImage()\n",
        "ksampler = KSampler()\n",
        "vae_decode = VAEDecode()\n",
        "save_image = SaveImage()\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "def generate_image(\n",
        "    positive_prompt: str = \"anime girl with massive fennec ears and a big fluffy fox tail with long wavy blonde hair and blue eyes wearing a pink sweater a large oversized black winter coat and a long blue maxi skirt and large winter boots and a red scarf and large gloves sitting in a sled sledding fast down a snow mountain\",\n",
        "    negative_prompt: str = \"bad ugly jpeg artifacts\",\n",
        "    width: int = 1024,\n",
        "    height: int = 1024,\n",
        "    seed: int = 147638433643733,\n",
        "    steps: int = 28,\n",
        "    cfg_scale: float = 1.0,\n",
        "    sampler_name: str = \"lcm\",\n",
        "    scheduler: str = \"simple\",\n",
        "    shift: float = 6.0\n",
        "):\n",
        "    with torch.inference_mode():\n",
        "        print(\"Loading CLIP models...\")\n",
        "        clip = clip_loader.load_clip(\n",
        "            clip_g,\n",
        "            clip_l,\n",
        "            t5xxl,\n",
        "            llama\n",
        "        )[0]\n",
        "\n",
        "        print(\"Encoding prompts...\")\n",
        "        positive = clip_encode_positive.encode(clip, positive_prompt)[0]\n",
        "        negative = clip_encode_negative.encode(clip, negative_prompt)[0]\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Creating empty latent...\")\n",
        "        empty_latent = empty_latent_image.generate(width, height, 1)[0]\n",
        "\n",
        "        print(\"Loading UNet model...\")\n",
        "        model = unet_loader.load_unet(hidream_model)[0]\n",
        "        model = model_sampling.patch(model, shift)[0]\n",
        "\n",
        "        print(\"Generating Image...\")\n",
        "        sampled = ksampler.sample(\n",
        "            model=model,\n",
        "            seed=seed,\n",
        "            steps=steps,\n",
        "            cfg=cfg_scale,\n",
        "            sampler_name=sampler_name,\n",
        "            scheduler=scheduler,\n",
        "            positive=positive,\n",
        "            negative=negative,\n",
        "            latent_image=empty_latent\n",
        "        )[0]\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Loading VAE...\")\n",
        "        vae = vae_loader.load_vae(\"ae.safetensors\")[0]\n",
        "\n",
        "        try:\n",
        "            print(\"Decoding image...\")\n",
        "            decoded = vae_decode.decode(vae, sampled)[0]\n",
        "\n",
        "            del vae\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            print(\"Saving image...\")\n",
        "            output_path = save_image.save_images(decoded, \"ComfyUI\")[\"ui\"][\"images\"][0][\"filename\"]\n",
        "            full_path = f\"/content/ComfyUI/output/{output_path}\"\n",
        "\n",
        "            from IPython.display import display, Image\n",
        "            display(Image(filename=full_path))\n",
        "\n",
        "            return full_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during decoding/saving: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory()\n",
        "\n",
        "print(\"✅ Environment Setup Complete!\")\n",
        "\n",
        "# Example usage:\n",
        "# generate_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B48efDl35VBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use this section if you selected `fast` as the hidream_fp8_version** in \"Setup Environment\""
      ],
      "metadata": {
        "id": "QB3AR9Zx-QVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Image (Fast Version)\n",
        "positive_prompt = \"A sharp image of a beautiful 25-year-old curvy and busty blonde woman with long wavy hair, wearing a low-neck top and a short skirt, running toward the camera with a full-body view, dynamic motion, dramatic lighting, urban background. She looks slightly scared or determined. Two uniformed women in matching outfits are chasing her from behind. Cinematic style, shallow depth of field, high detail, full-body framing, natural lighting.\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"bad ugly jpeg artifacts blurry, extra limbs, distorted face, bad anatomy, low resolution, out of frame, cropped, low detail, unrealistic proportions, artifacts, dull\" # @param {\"type\":\"string\"}\n",
        "width = 768 # @param {\"type\":\"integer\", \"min\":512, \"max\":2048}\n",
        "height = 512 # @param {\"type\":\"integer\", \"min\":512, \"max\":2048}\n",
        "seed = 0 # @param {\"type\":\"integer\"}\n",
        "steps = 16 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
        "cfg_scale = 1.0 # @param {\"type\":\"number\", \"min\":0.1, \"max\":20.0}\n",
        "sampler_name = \"dpmpp_2m\" # @param [\"lcm\", \"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
        "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
        "shift = 3.0 # @param {\"type\":\"number\", \"min\":0.0, \"max\":10.0}\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "# Generate the image\n",
        "output_path = generate_image(\n",
        "    positive_prompt=positive_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg_scale=cfg_scale,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    shift=shift\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gHM0_hQFxWvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KKFt5NKo5Zrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use this section if you selected `dev` as the hidream_fp8_version** in \"Setup Environment\""
      ],
      "metadata": {
        "id": "D3cquHaK_WN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Image (Dev Version)\n",
        "positive_prompt = \"A sharp image of a beautiful 25-year-old curvy and busty blonde woman with long wavy hair, wearing a low-neck top and a short skirt, running toward the camera with a full-body view, dynamic motion, dramatic lighting, urban background. She looks slightly scared or determined. Two uniformed women in matching outfits are chasing her from behind. Cinematic style, shallow depth of field, high detail, full-body framing, natural lighting.\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"bad ugly jpeg artifacts blurry, extra limbs, distorted face, bad anatomy, low resolution, out of frame, cropped, low detail, unrealistic proportions, artifacts, dull\" # @param {\"type\":\"string\"}\n",
        "width = 768 # @param {\"type\":\"integer\", \"min\":512, \"max\":2048}\n",
        "height = 512 # @param {\"type\":\"integer\", \"min\":512, \"max\":2048}\n",
        "seed = 0 # @param {\"type\":\"integer\"}\n",
        "steps = 28 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
        "cfg_scale = 1.0 # @param {\"type\":\"number\", \"min\":0.1, \"max\":20.0}\n",
        "sampler_name = \"euler\" # @param [\"lcm\", \"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
        "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
        "shift = 6.0 # @param {\"type\":\"number\", \"min\":0.0, \"max\":10.0}\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "# Generate the image\n",
        "output_path = generate_image(\n",
        "    positive_prompt=positive_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg_scale=cfg_scale,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    shift=shift\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "C-Mt6P2DZ_U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p7xJ_nSk55X6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use this section if you selected `full` as the hidream_fp8_version** in \"Setup Environment\""
      ],
      "metadata": {
        "id": "9K7B3Cdy_jrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Image (Full Version)\n",
        "positive_prompt = \"A sharp image of a beautiful 25-year-old curvy and busty blonde woman with long wavy hair, wearing a low-neck top and a short skirt, running toward the camera with a full-body view, dynamic motion, dramatic lighting, urban background. She looks slightly scared or determined. Two uniformed women in matching outfits are chasing her from behind. Cinematic style, shallow depth of field, high detail, full-body framing, natural lighting.\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"bad ugly jpeg artifacts blurry, extra limbs, distorted face, bad anatomy, low resolution, out of frame, cropped, low detail, unrealistic proportions, artifacts, dull\" # @param {\"type\":\"string\"}\n",
        "width = 768 # @param {\"type\":\"integer\", \"min\":512, \"max\":2048}\n",
        "height = 512 # @param {\"type\":\"integer\", \"min\":512, \"max\":2048}\n",
        "seed = 0 # @param {\"type\":\"integer\"}\n",
        "steps = 50 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
        "cfg_scale = 5.0 # @param {\"type\":\"number\", \"min\":0.1, \"max\":20.0}\n",
        "sampler_name = \"uni_pc\" # @param [\"lcm\", \"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
        "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
        "shift = 3.0 # @param {\"type\":\"number\", \"min\":0.0, \"max\":10.0}\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "# Generate the image\n",
        "output_path = generate_image(\n",
        "    positive_prompt=positive_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg_scale=cfg_scale,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    shift=shift\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WlCU9T4R0bu5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}